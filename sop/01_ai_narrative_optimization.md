# SOP-01: AI Narrative Optimization Pipeline

## 1. Document Control

| Field | Value |
|-------|-------|
| **SOP Number** | SOP-01 |
| **Title** | AI Narrative Optimization Pipeline |
| **Version** | 2.0 |
| **Effective Date** | 2024-12-04 |
| **Last Reviewed** | 2024-12-05 |
| **Owner** | Development Team |

---

## 2. Purpose

This procedure defines the iterative process for improving AI-generated narrative text quality in Wayfarer. It establishes a human-AI feedback loop that:

- Validates AI output against mechanical game context
- Identifies prompt deficiencies through systematic testing
- Documents improvements for reproducibility

---

## 3. Scope

### In Scope

| Component | Description |
|-----------|-------------|
| Situation narratives | AI-generated scene descriptions |
| Prompt templates | ScenePromptBuilder output |
| Quality metrics | Length, context markers, entity consistency |
| Test fixtures | Predefined scenarios for validation |

### Out of Scope

| Component | Reason |
|-----------|--------|
| Dialogue generation | Separate system (not yet implemented) |
| Mechanical content | Generated by archetypes, not AI |
| Model selection | Covered in infrastructure documentation |

---

## 4. Roles and Responsibilities

| Role | Responsibility |
|------|----------------|
| **Developer** | Execute procedure, modify prompts, run tests |
| **AI Assistant** | Analyze results, suggest improvements, track patterns |
| **Reviewer** | Approve prompt changes, validate quality thresholds |

---

## 5. Prerequisites

### 5.1 Environment Requirements

| Requirement | Verification |
|-------------|--------------|
| Ollama running | System tray icon visible |
| Model loaded | `curl http://localhost:11434/api/tags` returns model list |
| Project builds | `dotnet build` succeeds |

### 5.2 Key Files

| File | Purpose |
|------|---------|
| `src/Subsystems/Scene/ScenePromptBuilder.cs` | **PRODUCTION PROMPT** - Edit to change AI behavior |
| `Wayfarer.Tests.Project/AI/NarrativeTestFixtures.cs` | Test fixtures with validation criteria |
| `Wayfarer.Tests.Project/AI/NarrativeEvaluationTests.cs` | Test runner and validation logic |
| `Wayfarer.Tests.Project/AI/NarrativeQualityReport.cs` | JSON export structure |
| `src/Infrastructure/AI/OllamaConfiguration.cs` | Model configuration |

---

## 6. Procedure

### 6.1 Architecture Overview

```
+-----------------------+     +----------------------+     +---------------------+
|  ScenePromptBuilder   | --> |   Ollama (Local AI)  | --> |  Quality Reports    |
|  (Prompt Template)    |     |   gemma3:12b-it-qat  |     |  (JSON Export)      |
+-----------------------+     +----------------------+     +---------------------+
         |                                                          |
         |                                                          v
         |                                                +-----------------------+
         |<-----------------------------------------------| Human/AI Analysis     |
         |              Prompt Improvements               | (This Procedure)      |
         +------------------------------------------------+-----------------------+
```

### 6.2 Step 1: Establish Baseline

**Objective:** Generate current AI output for all test fixtures.

**Actions:**

1. Build the project (from repository root):
   ```bash
   dotnet build
   ```

2. Run evaluation tests:
   ```bash
   dotnet test --filter "Evaluate_AllSituationFixtures_WithExport" --no-build
   ```

3. Locate output file:
   ```bash
   ls Wayfarer.Tests.Project/AI/narrative_eval_*.json
   ```

**Expected Outcome:** JSON file created with test results for all fixtures.

**Verification:** File exists and contains `testResults` array with entries for each fixture.

---

### 6.3 Step 2: Analyze Results

**Objective:** Identify quality issues in AI output.

**CRITICAL:** Tests passing does NOT mean output is perfect. Tests validate minimum thresholds only.

#### 6.3.1 Automated Validation (in test results)

| Check | What It Validates |
|-------|-------------------|
| `lengthResult` | Character count within `ExpectedLengthRange` |
| `contextResult` | Required atmospheric markers present |
| `passed` | Overall pass/fail status |
| `allFailureReasons` | Specific issues for failures |

#### 6.3.2 Manual Review (ALWAYS required)

Even for passing tests, review each `response` field for:

| Issue Type | Example | Indicates |
|------------|---------|-----------|
| Markdown in output | `**Thornfield Manor**` | Missing formatting rule in prompt |
| Grammar issues | "ahead of Manor" | Prompt guidance or model limitation |
| Weak context usage | Guard scene missing "gate" | Context emphasis too weak |
| Repetitive patterns | Same structure across all | Need variety instruction |
| Fabricated names | Names not in context | Entity rules too weak |

**Expected Outcome:** List of specific issues to address.

---

### 6.4 Step 3: Identify Root Cause

**Objective:** Map issues to their fix locations.

| Failure Pattern | Root Cause | Fix Location |
|-----------------|------------|--------------|
| Too long/short | Length guidance weak | `ScenePromptBuilder.cs` output rules |
| Missing context markers | AI not using context | `ScenePromptBuilder.cs` context emphasis |
| Invented names | AI hallucinating | `ScenePromptBuilder.cs` name rules |
| Wrong tone | Hints unclear | `ScenePromptBuilder.cs` narrative direction |
| Narrow markers failing | Markers too literal | `NarrativeTestFixtures.cs` marker lists |

**Decision Point:** Is this a prompt issue or a fixture issue?

- **Prompt issue:** AI produces wrong output given correct instructions
- **Fixture issue:** Test markers too narrow to catch valid synonyms

---

### 6.5 Step 4: Implement Fix

**Objective:** Modify prompt template or test fixtures.

#### 6.5.1 For Prompt Issues

Edit `ScenePromptBuilder.BuildSituationPrompt()`:

| Issue | Fix Approach |
|-------|--------------|
| Length issues | Strengthen character count guidance with explicit limits |
| Formatting issues | Add explicit "no markdown" rule |
| Cliches | Add anti-cliche instructions |
| Entity names | Add examples of correct vs incorrect usage |
| Tone problems | Clarify narrative direction in hints section |

#### 6.5.2 For Fixture Issues

Edit `NarrativeTestFixtures.cs`:

| Issue | Fix Approach |
|-------|--------------|
| Narrow markers | Add synonyms (e.g., "chill", "cold", "frost" for winter) |
| Strict thresholds | Adjust `RequiredMarkerCount` |
| Wrong length range | Update `ExpectedLengthRange` |

**Verification:** Code compiles after changes.

---

### 6.6 Step 5: Validate Improvement

**Objective:** Confirm fix resolves the issue without regression.

**Actions:**

1. Rebuild (required after code changes):
   ```bash
   dotnet test --filter "Evaluate_AllSituationFixtures_WithExport"
   ```
   Note: Omit `--no-build` to ensure changes are compiled.

2. Compare new JSON to previous baseline.

3. Verify:
   - Target issue is resolved
   - No new failures introduced
   - Output quality improved (manual review)

**Decision Point:**

| Result | Action |
|--------|--------|
| Improved, no regressions | Document in revision history, proceed |
| Improved but new issues | Return to Step 3 |
| No improvement | Reconsider root cause analysis |
| Regression | Revert and reconsider approach |

---

## 7. Validation Philosophy

### 7.1 Additive, Not Conflicting

AI narrative is **ADDITIVE** to mechanical context, not **CONFLICTING**:

| Scenario | Result | Reason |
|----------|--------|--------|
| AI writes pure atmosphere without names | PASS | Valid stylistic choice |
| AI uses correct entity names from context | PASS | Correct reference |
| AI invents different names | FAIL | Breaks mechanical consistency |

### 7.2 Why This Matters

Both AI narrative AND mechanical entities display in the UI. Consistency is mandatory:

- Player sees NPC name "Martha Holloway" in character panel
- AI narrative must NOT call her "Sarah"
- AI CAN say "the innkeeper" (generic) OR "Martha Holloway" (exact)

### 7.3 Two-Tier Validation

| Tier | Method | What It Catches |
|------|--------|-----------------|
| Automated | Test assertions | Length, context markers (threshold-based) |
| Manual | Human/AI review | Fabricated names, tone, grammar, quality |

---

## 8. Troubleshooting

### 8.1 Tests Pass in 2ms (Not Actually Running)

**Symptoms:**
- Test "passes" instantly
- No JSON file created

**Causes:**
1. Ollama health check failed (test skips)
2. Old DLL used (`--no-build` after code changes)

**Resolution:**
1. Always rebuild after code changes: `dotnet test` (without `--no-build`)
2. Verify Ollama: `curl http://localhost:11434/api/tags`
3. Check for JSON output file

---

### 8.2 Tests Skip (Ollama Not Available)

**Symptoms:**
- `SKIPPED: Ollama not available`
- Test passes in 2ms (suspiciously fast)

**Understanding Ollama on Windows:**
- Runs as Windows startup app (system tray)
- Listens on port 11434
- NEVER call `ollama serve` (creates conflict)
- Uses IPv6 (`::1`) - always use `localhost` not `127.0.0.1`

**Resolution:**
1. Check system tray for Ollama icon
2. If missing: Start from Start Menu ("Ollama")
3. Wait 5-10 seconds for initialization
4. Verify: `curl http://localhost:11434/api/tags`

**If Ollama Unresponsive:**
1. Kill processes: `taskkill //F //IM ollama.exe`
2. Also: `taskkill //F //IM "ollama app.exe"`
3. Restart from Start Menu
4. Wait 10 seconds before tests

---

### 8.3 AI Responses Too Long

**Symptom:** `Too long: 450 chars (max: 200)`

**Resolution:** Strengthen length guidance in `ScenePromptBuilder.cs`:
- Add explicit character counts
- Add "count carefully" instruction
- Consider "ONE sentence only" constraint

---

### 8.4 AI Invents Names

**Symptom:** Response contains names not in context (detected via manual review)

**Resolution:** Add entity name rules to `ScenePromptBuilder.cs`:
- Explicit examples of correct usage (given names OR generic terms)
- Explicit examples of incorrect usage (invented names)

---

### 8.5 AI Ignores Context

**Symptom:** `Context insufficiently referenced: 0/1 markers found`

**Root Cause Usually in Fixtures:**
- Context markers too narrow/literal
- AI uses synonyms: "chill" instead of "fog"

**Resolution:**
- Add multiple synonyms per concept in `NarrativeTestFixtures.cs`
- Set `RequiredMarkerCount = 1` (only one synonym needs to appear)

---

## 9. Metrics and Quality Indicators

### 9.1 Pass Rate

| Metric | Target | Action if Below |
|--------|--------|-----------------|
| Overall pass rate | 100% | Investigate all failures |
| Length compliance | 100% | Adjust prompt length rules |
| Context marker hits | 80%+ | Expand marker synonyms |

### 9.2 Quality Indicators (Manual Assessment)

| Indicator | Good | Poor |
|-----------|------|------|
| Variety | Different structures across fixtures | Repetitive patterns |
| Atmosphere | Evocative sensory details | Generic descriptions |
| Consistency | Names match context | Fabricated elements |
| Formatting | Plain text | Markdown artifacts |

---

## 10. Model Configuration

**Default Model:** `gemma3:12b-it-qat` (defined in `OllamaConfiguration.cs`)

**To Test Different Models:**
1. Edit `OllamaConfiguration.DefaultModel`
2. Re-run tests
3. Compare JSON results
4. Document findings in revision history

---

## 11. Revision History

### Version 2.0 (2024-12-04): Stricter Length + Anti-Cliche

**Problem Identified:** v1 prompts produced responses 100-170 chars with repetitive patterns ("dust motes dance" appeared in multiple responses) and occasional markdown artifacts.

**Changes Made:**
- Changed character limit from "200 max" to "50-120 strict"
- Added explicit "ONE sentence only" instruction
- Added anti-cliche rule to avoid repetitive openings
- Clarified "pure sensory atmosphere, no character actions"
- Added "plain text only, no markdown" rule

**Results:**

| Fixture | v1 Length | v2 Length | Improvement |
|---------|-----------|-----------|-------------|
| InnkeeperLodgingNegotiation | 103-133 | 83 | More concise |
| GuardCheckpointConfrontation | 133-176 | 78 | More concise |
| MerchantInformationExchange | 131-145 | 79 | More concise |
| ScholarResearchAssistance | 143-166 | 93 | No "dust motes" |
| ForestPathEncounter | 125-136 | 94 | More concise |

**Model Artifacts Discovered:** Gemma3 sometimes appends end-of-turn tokens. Added post-processing in `SceneNarrativeService.CleanAIResponse()`.

---

### Version 1.0 (Initial)

**Files Created:**
- `ScenePromptBuilder.cs` - Initial prompt template
- `NarrativeTestFixtures.cs` - Test fixtures and validation model
- `NarrativeEvaluationTests.cs` - Validation logic

---

## 12. References

| Document | Purpose |
|----------|---------|
| [arc42/08_crosscutting_concepts.md](../arc42/08_crosscutting_concepts.md) Section 8.28 | Two-Pass Generation Architecture |
| [gdd/05_content.md](../gdd/05_content.md) | Content structure and archetypes |
| [OllamaConfiguration.cs](../src/Infrastructure/AI/OllamaConfiguration.cs) | Model settings |

---

## 13. Approval

| Role | Name | Date |
|------|------|------|
| Author | Development Team | 2024-12-04 |
| Reviewer | - | - |
| Approver | - | - |
