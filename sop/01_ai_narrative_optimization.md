# SOP-01: AI Narrative Optimization Pipeline

## 1. Document Control

| Field | Value |
|-------|-------|
| **SOP Number** | SOP-01 |
| **Title** | AI Narrative Optimization Pipeline |
| **Version** | 2.1 |
| **Effective Date** | 2025-12-05 |
| **Last Reviewed** | 2025-12-05 |
| **Owner** | Development Team |

---

## 2. Purpose

This procedure defines the iterative process for improving AI-generated narrative text quality in Wayfarer. It establishes a human-AI feedback loop that:

- Validates AI output against mechanical game context
- Identifies prompt deficiencies through systematic testing
- Documents improvements for reproducibility

---

## 3. Scope

### In Scope

| Component | Description |
|-----------|-------------|
| Situation narratives | AI-generated scene descriptions |
| Prompt templates | ScenePromptBuilder output |
| Quality metrics | Length, context markers, entity consistency |
| Test fixtures | Predefined scenarios for validation |

### Out of Scope

| Component | Reason |
|-----------|--------|
| Dialogue generation | Separate system (not yet implemented) |
| Mechanical content | Generated by archetypes, not AI |
| Model selection | Covered in infrastructure documentation |

---

## 4. Roles and Responsibilities

| Role | Responsibility |
|------|----------------|
| **Developer** | Execute procedure, modify prompts, run tests |
| **AI Assistant** | Analyze results, suggest improvements, track patterns |
| **Reviewer** | Approve prompt changes, validate quality thresholds |

---

## 5. Prerequisites

### 5.1 Environment Requirements

| Requirement | Verification |
|-------------|--------------|
| Ollama running | System tray icon visible |
| Model loaded | `curl http://localhost:11434/api/tags` returns model list |
| Project builds | `dotnet build` succeeds |

### 5.2 Key Files

| File | Purpose |
|------|---------|
| `src/Subsystems/Scene/ScenePromptBuilder.cs` | **PRODUCTION PROMPT** - Edit to change AI behavior |
| `Wayfarer.Tests.Project/AI/NarrativeTestFixtures.cs` | Test fixtures with validation criteria |
| `Wayfarer.Tests.Project/AI/NarrativeEvaluationTests.cs` | Test runner and validation logic |
| `Wayfarer.Tests.Project/AI/NarrativeQualityReport.cs` | JSON export structure |
| `src/Infrastructure/AI/OllamaConfiguration.cs` | Model configuration |

---

## 6. Procedure

### 6.1 Architecture Overview

```
+-----------------------+     +----------------------+     +---------------------+
|  ScenePromptBuilder   | --> |   Ollama (Local AI)  | --> |  Quality Reports    |
|  (Prompt Template)    |     |   gemma3:12b-it-qat  |     |  (JSON Export)      |
+-----------------------+     +----------------------+     +---------------------+
         |                                                          |
         |                                                          v
         |                                                +-----------------------+
         |<-----------------------------------------------| Human/AI Analysis     |
         |              Prompt Improvements               | (This Procedure)      |
         +------------------------------------------------+-----------------------+
```

### 6.2 Step 1: Establish Baseline

**Objective:** Generate current AI output for all test fixtures.

**Actions:**

1. Build the project (from repository root):
   ```bash
   dotnet build
   ```

2. Run evaluation tests:
   ```bash
   dotnet test --filter "Evaluate_AllSituationFixtures_WithExport" --no-build
   ```

3. Locate output file:
   ```bash
   ls Wayfarer.Tests.Project/AI/narrative_eval_*.json
   ```

**Expected Outcome:** JSON file created with test results for all fixtures.

**Verification:** File exists and contains `testResults` array with entries for each fixture.

---

### 6.3 Step 2: Analyze Results

**Objective:** Identify quality issues in AI output.

**CRITICAL:** Tests passing does NOT mean output is perfect. Tests validate minimum thresholds only.

#### 6.3.1 Automated Validation (in test results)

| Check | What It Validates |
|-------|-------------------|
| `lengthResult` | Character count within `ExpectedLengthRange` |
| `contextResult` | Required atmospheric markers present |
| `passed` | Overall pass/fail status |
| `allFailureReasons` | Specific issues for failures |

#### 6.3.2 Manual Review (ALWAYS required)

Even for passing tests, review each `response` field for:

| Issue Type | Example | Indicates |
|------------|---------|-----------|
| Markdown in output | `**Thornfield Manor**` | Missing formatting rule in prompt |
| Grammar issues | "ahead of Manor" | Prompt guidance or model limitation |
| Weak context usage | Guard scene missing "gate" | Context emphasis too weak |
| Repetitive patterns | Same structure across all | Need variety instruction |
| Fabricated names | Names not in context | Entity rules too weak |

**Expected Outcome:** List of specific issues to address.

---

### 6.4 Step 3: Identify Root Cause

**Objective:** Map issues to their fix locations.

| Failure Pattern | Root Cause | Fix Location |
|-----------------|------------|--------------|
| Too long/short | Length guidance weak | `ScenePromptBuilder.cs` output rules |
| Missing context markers | AI not using context | `ScenePromptBuilder.cs` context emphasis |
| Invented names | AI hallucinating | `ScenePromptBuilder.cs` name rules |
| Wrong tone | Hints unclear | `ScenePromptBuilder.cs` narrative direction |
| Narrow markers failing | Markers too literal | `NarrativeTestFixtures.cs` marker lists |

**Decision Point:** Is this a prompt issue or a fixture issue?

- **Prompt issue:** AI produces wrong output given correct instructions
- **Fixture issue:** Test markers too narrow to catch valid synonyms

---

### 6.5 Step 4: Implement Fix

**Objective:** Modify prompt template or test fixtures.

#### 6.5.1 For Prompt Issues

Edit `ScenePromptBuilder.BuildSituationPrompt()`:

| Issue | Fix Approach |
|-------|--------------|
| Length issues | Strengthen character count guidance with explicit limits |
| Formatting issues | Add explicit "no markdown" rule |
| Cliches | Add anti-cliche instructions |
| Entity names | Add examples of correct vs incorrect usage |
| Tone problems | Clarify narrative direction in hints section |

#### 6.5.2 For Fixture Issues

Edit `NarrativeTestFixtures.cs`:

| Issue | Fix Approach |
|-------|--------------|
| Narrow markers | Add synonyms (e.g., "chill", "cold", "frost" for winter) |
| Strict thresholds | Adjust `RequiredMarkerCount` |
| Wrong length range | Update `ExpectedLengthRange` |

**Verification:** Code compiles after changes.

---

### 6.6 Step 5: Validate Improvement

**Objective:** Confirm fix resolves the issue without regression.

**Actions:**

1. Rebuild (required after code changes):
   ```bash
   dotnet test --filter "Evaluate_AllSituationFixtures_WithExport"
   ```
   Note: Omit `--no-build` to ensure changes are compiled.

2. Compare new JSON to previous baseline.

3. Verify:
   - Target issue is resolved
   - No new failures introduced
   - Output quality improved (manual review)

**Decision Point:**

| Result | Action |
|--------|--------|
| Improved, no regressions | Document in revision history, proceed |
| Improved but new issues | Return to Step 3 |
| No improvement | Reconsider root cause analysis |
| Regression | Revert and reconsider approach |

---

## 7. Validation Philosophy

### 7.1 Additive, Not Conflicting

AI narrative is **ADDITIVE** to mechanical context, not **CONFLICTING**:

| Scenario | Result | Reason |
|----------|--------|--------|
| AI writes pure atmosphere without names | PASS | Valid stylistic choice |
| AI uses correct entity names from context | PASS | Correct reference |
| AI invents different names | FAIL | Breaks mechanical consistency |

### 7.2 Why This Matters

Both AI narrative AND mechanical entities display in the UI. Consistency is mandatory:

- Player sees NPC name "Martha Holloway" in character panel
- AI narrative must NOT call her "Sarah"
- AI CAN say "the innkeeper" (generic) OR "Martha Holloway" (exact)

### 7.3 Two-Tier Validation

| Tier | Method | What It Catches |
|------|--------|-----------------|
| Automated | Test assertions | Length, context markers (threshold-based) |
| Manual | Human/AI review | Fabricated names, tone, grammar, quality |

---

## 8. Troubleshooting

### 8.1 Tests Pass in 2ms (Not Actually Running)

**Symptoms:**
- Test "passes" instantly
- No JSON file created

**Causes:**
1. Ollama health check failed (test skips)
2. Old DLL used (`--no-build` after code changes)

**Resolution:**
1. Always rebuild after code changes: `dotnet test` (without `--no-build`)
2. Verify Ollama: `curl http://localhost:11434/api/tags`
3. Check for JSON output file

---

### 8.2 Health Check Fails Despite Ollama Running

**Symptoms:**
- `[Startup] Ollama not available` even though Ollama is running in system tray
- `curl http://127.0.0.1:11434/api/tags` times out or refuses connection
- `curl http://localhost:11434/api/tags` succeeds

**Root Cause: IPv4 vs IPv6 Binding**

On Windows, Ollama binds to IPv6 (`::1`) by default, NOT IPv4 (`127.0.0.1`).

| Address | Protocol | Works with Ollama? |
|---------|----------|-------------------|
| `localhost` | Resolves to both IPv4 and IPv6 | ✅ YES |
| `127.0.0.1` | IPv4 only | ❌ NO |
| `::1` | IPv6 only | ✅ YES |

**Configuration Architecture (HIGHLANDER Compliant):**

| Source | Purpose | Overrides? |
|--------|---------|------------|
| `OllamaConfiguration.cs` constants | SINGLE SOURCE OF TRUTH | N/A - this IS the truth |
| `OLLAMA_BASE_URL` environment variable | CI/CD machine-specific override | Yes (for deployment only) |
| `appsettings.json` | FORBIDDEN for Ollama config | N/A - not supported |

**Resolution:**

1. Verify compile-time default in `OllamaConfiguration.cs`:
   ```csharp
   public const string DefaultBaseUrl = "http://localhost:11434";
   ```

2. If CI/CD needs different URL, set environment variable:
   ```bash
   export OLLAMA_BASE_URL="http://your-ollama-host:11434"
   ```

3. Verify connectivity: `curl http://localhost:11434/api/tags`

**Why `localhost` Not `127.0.0.1`:**
- `localhost` resolves to both IPv4 (127.0.0.1) AND IPv6 (::1)
- Ollama on Windows binds to IPv6 by default
- `127.0.0.1` is IPv4-only, cannot reach IPv6 socket
- Using `localhost` guarantees connectivity regardless of Ollama's binding

---

### 8.3 Tests Skip (Ollama Not Available)

**Symptoms:**
- `SKIPPED: Ollama not available`
- Test passes in 2ms (suspiciously fast)

**Understanding Ollama on Windows:**
- Runs as Windows startup app (system tray)
- Listens on port 11434
- NEVER call `ollama serve` (creates conflict)
- Uses IPv6 (`::1`) - always use `localhost` not `127.0.0.1`

**Resolution:**
1. Check system tray for Ollama icon
2. If missing: Start from Start Menu ("Ollama")
3. Wait 5-10 seconds for initialization
4. Verify: `curl http://localhost:11434/api/tags`

**If Ollama Unresponsive:**
1. Kill processes: `taskkill //F //IM ollama.exe`
2. Also: `taskkill //F //IM "ollama app.exe"`
3. Restart from Start Menu
4. Wait 10 seconds before tests

---

### 8.4 AI Responses Too Long

**Symptom:** `Too long: 450 chars (max: 200)`

**Resolution:** Strengthen length guidance in `ScenePromptBuilder.cs`:
- Add explicit character counts
- Add "count carefully" instruction
- Consider "ONE sentence only" constraint

---

### 8.5 AI Invents Names

**Symptom:** Response contains names not in context (detected via manual review)

**Resolution:** Add entity name rules to `ScenePromptBuilder.cs`:
- Explicit examples of correct usage (given names OR generic terms)
- Explicit examples of incorrect usage (invented names)

---

### 8.6 AI Ignores Context

**Symptom:** `Context insufficiently referenced: 0/1 markers found`

**Root Cause Usually in Fixtures:**
- Context markers too narrow/literal
- AI uses synonyms: "chill" instead of "fog"

**Resolution:**
- Add multiple synonyms per concept in `NarrativeTestFixtures.cs`
- Set `RequiredMarkerCount = 1` (only one synonym needs to appear)

---

## 9. Metrics and Quality Indicators

### 9.1 Pass Rate

| Metric | Target | Action if Below |
|--------|--------|-----------------|
| Overall pass rate | 100% | Investigate all failures |
| Length compliance | 100% | Adjust prompt length rules |
| Context marker hits | 80%+ | Expand marker synonyms |

### 9.2 Quality Indicators (Manual Assessment)

| Indicator | Good | Poor |
|-----------|------|------|
| Variety | Different structures across fixtures | Repetitive patterns |
| Atmosphere | Evocative sensory details | Generic descriptions |
| Consistency | Names match context | Fabricated elements |
| Formatting | Plain text | Markdown artifacts |

---

## 10. Model Configuration

**Default Model:** `gemma3:12b-it-qat` (defined in `OllamaConfiguration.cs`)

**To Test Different Models:**
1. Edit `OllamaConfiguration.DefaultModel`
2. Re-run tests
3. Compare JSON results
4. Document findings in revision history

---

## 11. Revision History

### Version 2.0 (2024-12-04): Stricter Length + Anti-Cliche

**Problem Identified:** v1 prompts produced responses 100-170 chars with repetitive patterns ("dust motes dance" appeared in multiple responses) and occasional markdown artifacts.

**Changes Made:**
- Changed character limit from "200 max" to "50-120 strict"
- Added explicit "ONE sentence only" instruction
- Added anti-cliche rule to avoid repetitive openings
- Clarified "pure sensory atmosphere, no character actions"
- Added "plain text only, no markdown" rule

**Results:**

| Fixture | v1 Length | v2 Length | Improvement |
|---------|-----------|-----------|-------------|
| InnkeeperLodgingNegotiation | 103-133 | 83 | More concise |
| GuardCheckpointConfrontation | 133-176 | 78 | More concise |
| MerchantInformationExchange | 131-145 | 79 | More concise |
| ScholarResearchAssistance | 143-166 | 93 | No "dust motes" |
| ForestPathEncounter | 125-136 | 94 | More concise |

**Model Artifacts Discovered:** Gemma3 sometimes appends end-of-turn tokens. Added post-processing in `SceneNarrativeService.CleanAIResponse()`.

---

### Version 2.1 (2025-12-05): Tone Priority + Marker Expansion

**Problems Identified:**

| Issue | Fixture | Symptom | Root Cause |
|-------|---------|---------|------------|
| False Negative | ScholarResearchAssistance | 0/1 markers found despite excellent output | Markers too narrow (missing synonyms) |
| Tone Mismatch | InnkeeperLodgingNegotiation | "damp chill" instead of "warm" | Weather context overriding tone hint |

**Analysis:**

1. **ScholarResearchAssistance False Negative:**
   - AI produced: `"The aged parchment under Professor Ashworth's table smelled faintly of cedar and forgotten ink."`
   - This is HIGH QUALITY output: uses NPC name correctly, scholarly atmosphere, sensory detail
   - Failed because markers `["archive", "library", "scholar", "dusty", "tomes", "books", "quiet", "morning"]` didn't include synonyms the AI used
   - AI used: "parchment" (≈ tomes/books), "Professor Ashworth" (≈ scholar), "aged" (≈ dusty), "ink", "cedar"

2. **InnkeeperLodgingNegotiation Tone Mismatch:**
   - Context: Tone = "warm", Weather = "Rain"
   - AI produced: `"A damp chill seeped through the worn wooden floors..."`
   - Weather appeared in prompt BEFORE Narrative Direction
   - No instruction told AI to prioritize tone over weather for emotional atmosphere

**Changes Made:**

| File | Change |
|------|--------|
| `NarrativeTestFixtures.cs` | Expanded ScholarResearchAssistance markers from 8 → 22 synonyms |
| `ScenePromptBuilder.cs` | Added Output Rule 7: "TONE PRIORITY: The Narrative Direction tone OVERRIDES weather for emotional atmosphere." |

**Marker Expansion (ScholarResearchAssistance):**

```
Before: ["archive", "library", "scholar", "dusty", "tomes", "books", "quiet", "morning"]

After:  ["archive", "antiquarian", "library", "scholar", "professor", "ashworth",
         "tomes", "books", "parchment", "scrolls", "paper", "ink",
         "dusty", "aged", "ancient", "old", "cedar", "musty",
         "quiet", "morning", "still", "silent"]
```

**Results:**

| Fixture | v2.0 Response | v2.1 Response | Improvement |
|---------|---------------|---------------|-------------|
| InnkeeperLodgingNegotiation | "A damp chill seeped..." | "The Weary Traveler Inn's hearth smoke clung **warmly**..." | Tone fixed |
| ScholarResearchAssistance | FAILED (0 markers) | PASSED (4 markers: archive, antiquarian, paper, aged) | False negative fixed |

**Pass Rate:** 80% → **100%**

**Lessons Learned:**

1. **Marker Philosophy:** Include synonyms generously. AI is creative with vocabulary:
   - Entity name fragments (professor, ashworth, antiquarian)
   - Material synonyms (tomes, books, parchment, paper, scrolls)
   - Atmospheric synonyms (dusty, aged, ancient, musty, old)

2. **Prompt Ordering:** Later sections may have less influence. Explicit priority instructions needed when context conflicts (weather vs tone).

3. **False Negatives > False Positives:** Better to have broad markers that occasionally pass weak output than narrow markers that fail good output. Manual review catches quality issues; automated tests catch regressions.

---

### Version 1.0 (Initial)

**Files Created:**
- `ScenePromptBuilder.cs` - Initial prompt template
- `NarrativeTestFixtures.cs` - Test fixtures and validation model
- `NarrativeEvaluationTests.cs` - Validation logic

---

## 12. References

| Document | Purpose |
|----------|---------|
| [arc42/08_crosscutting_concepts.md](../arc42/08_crosscutting_concepts.md) Section 8.28 | Two-Pass Generation Architecture |
| [gdd/05_content.md](../gdd/05_content.md) | Content structure and archetypes |
| [OllamaConfiguration.cs](../src/Infrastructure/AI/OllamaConfiguration.cs) | Model settings |

---

## 13. Approval

| Role | Name | Date |
|------|------|------|
| Author | Development Team | 2024-12-04 |
| Reviewer | - | - |
| Approver | - | - |
